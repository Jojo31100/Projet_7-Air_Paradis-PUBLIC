{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPzEtG76gYB2yRW2gpR1Wil",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jojo31100/Projet_7-Air_Paradis-PUBLIC/blob/main/AirParadis_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Projet n°7 - Air Paradis : réalisez une analyse de sentiments grâce au Deep Learning**"
      ],
      "metadata": {
        "id": "nc9Bkoe9ME9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Lien vers le projet et les attendus](https://openclassrooms.com/fr/paths/795/projects/1516/)\n",
        "\n",
        "**Comment allez-vous procéder ?**\n",
        "\n",
        "Cette mission suit un scénario de projet professionnel.\n",
        "\n",
        "Vous pouvez suivre les étapes pour vous aider à réaliser vos livrables.\n",
        "\n",
        "Avant de démarrer, nous vous conseillons de :\n",
        "\n",
        "- lire toute la mission et ses documents liés ;\n",
        "- prendre des notes sur ce que vous avez compris ;\n",
        "- consulter les étapes pour vous guider ;\n",
        "- préparer une liste de questions pour votre première session de mentorat.\n",
        "\n",
        "---\n",
        "\n",
        "**Prêt à mener la mission ?**\n",
        "\n",
        "Vous êtes ingénieur IA chez MIC (Marketing Intelligence Consulting), une entreprise de conseil spécialisée sur les problématiques de marketing digital.\n",
        "\n",
        "Dans deux semaines, vous avez rendez-vous avec Mme Aline, directrice marketing de la compagnie aérienne “Air Paradis”.\n",
        "\n",
        "Air Paradis a missionné votre cabinet pour créer un produit IA permettant d'anticiper les bad buzz sur les réseaux sociaux.\n",
        "\n",
        "Il est vrai que “Air Paradis” n'a pas toujours bonne presse sur les réseaux...\n",
        "\n",
        "En sortant d'un rendez-vous de cadrage avec les équipes de Air Paradis, vous avez noté les éléments suivants :\n",
        "\n",
        "- Air Paradis veut un prototype d'un produit IA permettant de prédire le sentiment associé à un tweet.\n",
        "\n",
        "- Données : pas de données clients chez Air Paradis. Solution : utiliser des [données Open Source](https://www.kaggle.com/kazanova/sentiment140) - ou en téléchargement direct à [ce lien](https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/AI+Engineer/Project+7%C2%A0-+D%C3%A9tectez+les+Bad+Buzz+gr%C3%A2ce+au+Deep+Learning/sentiment140.zip)\n",
        " - Description des données : des informations sur les tweets (utilisateur ayant posté, contenu, moment du post) et un label binaire (tweet exprimant un sentiment négatif ou non).\n",
        "\n",
        "- TO-DO :\n",
        " - Préparer un prototype fonctionnel du modèle. Le modèle est exposé via une API déployée sur le Cloud, appelée par une interface locale(notebook ou application Streamlit) qui envoie un tweet à l'API et récupère la prédiction de sentiment.\n",
        " - Préparer un support de présentation explicitant les méthodologies utilisées pour les différentes approches (attention : audience non technique).\n",
        "\n",
        "---\n",
        "\n",
        "Après avoir reçu votre compte-rendu, Marc, votre manager, vous a contacté pour, selon ses mots, “faire d'une pierre deux coups”.\n",
        "\n",
        "**De :** *Marc*\n",
        "\n",
        "**Envoyé :** *hier 17:14*\n",
        "\n",
        "**À :** *vous*\n",
        "\n",
        "**Objet :** *Air Paradis : complément*\n",
        "\n",
        "Salut\n",
        "\n",
        "Merci pour ton récap du meeting avec Air Paradis. J'ai l'impression que ça s'est bien passé !\n",
        "\n",
        "Je me disais... Puisque tu vas faire un proto pour ce client, j'ai l'intuition que ce produit pourrait se généraliser à d'autres cas d'usage.\n",
        "\n",
        "Tu voudrais bien en profiter pour tester plusieurs approches ?\n",
        "\n",
        "- approche “Modèle sur mesure simple”, pour développer rapidement un modèle classique (ex : régression logistique) permettant de prédire le sentiment associé à un tweet.\n",
        "- approche “Modèle sur mesure avancé” pour développer un modèle basé sur des réseaux de neurones profonds pour prédire le sentiment associé à un tweet. => C'est ce modèle que tu devras déployer et montrer à Air Paradis.\n",
        "\n",
        "Pour cette 2ème approche, tu penseras bien à essayer au moins deux word embeddings différents et à garder celui qui permet d'obtenir les meilleures performances. En complément, pourrais-tu également regarder l'apport en performance d'un modèle BERT ? Cela nous permettra de voir si nous devons investir dans ce type de modèle.\n",
        "\n",
        "Et en même ce serait top si tu pouvais mettre en oeuvre un bon exemple de démarche orientée MLOps, tu sais c'est la nouvelle priorité de notre directeur !\n",
        "\n",
        "J'aimerais que tu puisses démontrer à l'occasion de l'élaboration de ton prototype tout l'apport du MLOps, afin d'assurer une diffusion aux autres équipes :\n",
        "\n",
        "- d'abord réaliser une présentation synthétique des principes du MLOps et ses apports,\n",
        "- ensuite utiliser l'outil MLFlow, future référence pour notre société, pour assurer la gestion des expérimentations des modèles : tracking et reporting de l'entraînement des modèles, centralisation du stockage des modèles, et test du serving proposé par MLFlow,\n",
        "- mettre en oeuvre un pipeline de déploiement continu du modèle que tu auras choisi via une API (Git + Github + plateforme Cloud au choix), qui intègre également des tests unitaires automatisés,\n",
        "- et enfin initier un suivi de la performance du modèle en production. Pour cela tu utiliseras un service Azure Application Insight que tu auras créé pour l‘occasion :\n",
        " - Pour remonter des traces des tweets qui seraient considérés par l'utilisateur comme mal prédits : le texte du tweet et la prédiction.\n",
        " - Pour déclencher une alerte (envoi SMS ou mail) dans le cas d'un nombre trop important de tweet mal prédits (par exemple 3 tweets mal prédits en l'espace de 5 minutes).\n",
        " - Présenter une démarche qui pourrait être mise en oeuvre pour l'analyse de ces statistiques et l'amélioration du modèle dans le temps.\n",
        "\n",
        "Nous souhaitons limiter les coûts de mise en production de ce prototype, donc peux-tu privilégier une solution gratuite Cloud pour le déploiement de l'API de prédiction, par exemple Azure webapp (ASP F1 gratuit), PythonAnywhere, Heroku avec le package “student” de Github ou tout autre solution ?\n",
        "\n",
        "Si le modèle avancé est trop lourd et induit un dépassement des limites de taille des solutions gratuites, tu pourras tester le déploiement avec le modèle classique, ou bien utiliser des techniques de réduction de taille de ton modèle TensorFlow-Keras via une conversion en TensorFlow Lite.\n",
        "\n",
        "Merci d'avance !\n",
        "\n",
        "*Marc*\n",
        "\n",
        "PS : Ah au fait, tant que tu y es, tu pourras rédiger un petit article pour le blog à partir de ton travail de modélisation et de ta démarche orientée MLOps ?\n",
        "\n",
        "---\n",
        "\n",
        "Vous avez pris connaissance du mail, vous avez hâte de démarrer ce nouveau projet avec intérêt ! C'est parti !"
      ],
      "metadata": {
        "id": "K6FG_X1nMQwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialisation : chargement des bibliothèques Python et des fonctions globales"
      ],
      "metadata": {
        "id": "4uVmZXG_FJQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas\n",
        "import numpy\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import matplotlib.pyplot\n",
        "import seaborn\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score, auc, roc_auc_score, roc_curve\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "9iwJ-KHcFjC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################\n",
        "## DATAFRAME MAIN INFORMATIONS AT A GLANCE ##\n",
        "#############################################\n",
        "def _visualisationDataset(_inputDataframe, _pourcentageRemplissageTarget, _legendesGraph=\"No\"):\n",
        "    nbDonneesPresentesGlobal = 0\n",
        "    tailleDataframe = _inputDataframe.shape[0]\n",
        "    for index in _inputDataframe.columns:\n",
        "        nbIndividus = _inputDataframe[index].notna().sum()\n",
        "        nbNaN = _inputDataframe[index].isna().sum()\n",
        "        typeDonnee = _inputDataframe[index].dtype\n",
        "        pourcentageRemplissage = round((nbIndividus / tailleDataframe) * 100, 2)\n",
        "\n",
        "        if (pourcentageRemplissage >= _pourcentageRemplissageTarget):\n",
        "            ligne = f\"[>\\033[32m{_pourcentageRemplissageTarget}%\\033[0m] \"\n",
        "            ligne += f\"Variable : \\033[1m\\033[3m{index:<50}\\033[0m\"\n",
        "            ligne += f\"Remplissage : \\033[32m\\033[1m{str(pourcentageRemplissage).rjust(5)} %\\033[0m\"\n",
        "        else:\n",
        "            ligne = f\"[<\\033[31m{_pourcentageRemplissageTarget}%\\033[0m] \"\n",
        "            ligne += f\"Variable : \\033[1m\\033[3m{index:<50}\\033[0m\"\n",
        "            ligne += f\"Remplissage : \\033[31m\\033[1m{str(pourcentageRemplissage).rjust(5)} %\\033[0m\"\n",
        "        ligne += f\" (\\033[3m{str(nbIndividus).rjust(5)}\\033[0m individus/\\033[3m{tailleDataframe}\\033[0m)\"\n",
        "        ligne += f\"\\tNaN : \\033[1m{str(nbNaN).rjust(5)}\\033[0m\"\n",
        "        ligne += f\"\\tType : \\033[3m{str(typeDonnee):<5}\\033[0m\"\n",
        "        if (typeDonnee == \"object\"):\n",
        "            nbUniques = _inputDataframe[index].nunique()\n",
        "            ligne += f\"\\t(Individus uniques : \\033[1m{nbUniques}\\033[0m)\"\n",
        "        elif (typeDonnee == \"bool\"):\n",
        "            ligne += f\"\\t(\\\"0\\\" vs. \\\"1\\\" = \\033[1m{_inputDataframe[index].value_counts().get(True, 0)}\\033[0m vs. \\033[1m{_inputDataframe[index].value_counts().get(False, 0)}\\033[0m)\"\n",
        "        elif (typeDonnee == \"datetime64[ns]\"):\n",
        "            ligne += f\" -- TIME STAMP !\"\n",
        "        else:\n",
        "            min = round(_inputDataframe[index].min(), 2)\n",
        "            max = round(_inputDataframe[index].max(), 2)\n",
        "            moyenne = round(_inputDataframe[index].mean(), 2)\n",
        "            ligne += f\"\\t(Min = \\033[1m{min:<5}\\033[0m Max = \\033[1m{max:<5}\\033[0m Moyenne = \\033[1m{moyenne}\\033[0m)\"\n",
        "        print(ligne)\n",
        "        nbDonneesPresentesGlobal = nbDonneesPresentesGlobal + nbIndividus\n",
        "\n",
        "    print(\"\\nAu global \", nbDonneesPresentesGlobal, \" données sont présentes, sur un total de \", _inputDataframe.shape[0]*_inputDataframe.shape[1], \", soit un remplissage de \", round( ((nbDonneesPresentesGlobal*100)/(_inputDataframe.shape[0]*_inputDataframe.shape[1])), 2),\"%\", sep=\"\")\n",
        "    print(_inputDataframe.dropna().shape[0], \" individus ne comptent aucun \\\"NaN\\\"\", sep=\"\")\n",
        "    print(\"Taille du dataset : \", _inputDataframe.shape[0], \" individus, et \", _inputDataframe.shape[1], \" variables\\n\\n\", sep=\"\")\n",
        "\n",
        "    dataframeRepartitionTest = _inputDataframe.count()*100/_inputDataframe.shape[0]\n",
        "    matplotlib.pyplot.figure(figsize=(20, 5))\n",
        "    matplotlib.pyplot.title(\"Représentation graphique de répartition du contenu du dataset\")\n",
        "    matplotlib.pyplot.xlabel(\"Variables\")\n",
        "    matplotlib.pyplot.ylabel(\"Pourcentage de remplissage\")\n",
        "    matplotlib.pyplot.bar(dataframeRepartitionTest.index, dataframeRepartitionTest.values, color=\"skyblue\", edgecolor=\"black\")\n",
        "    matplotlib.pyplot.axhline(y=25, color=\"yellow\", linestyle=\"--\", linewidth=2)\n",
        "    matplotlib.pyplot.axhline(y=33, color=\"orange\", linestyle=\"--\", linewidth=2)\n",
        "    matplotlib.pyplot.axhline(y=50, color=\"red\", linestyle=\"-\", linewidth=2)\n",
        "    matplotlib.pyplot.axhline(y=66, color=\"orange\", linestyle=\"--\", linewidth=2)\n",
        "    matplotlib.pyplot.axhline(y=75, color=\"yellow\", linestyle=\"--\", linewidth=2)\n",
        "    if (_legendesGraph == \"No\"):\n",
        "        matplotlib.pyplot.xticks([])\n",
        "    else:\n",
        "        matplotlib.pyplot.xticks(rotation=80)\n",
        "        matplotlib.pyplot.xlim(-0.5, _inputDataframe.shape[1] - 0.5)\n",
        "        matplotlib.pyplot.show()\n",
        "\n",
        "#Rouge        : \\033[31m\n",
        "#Vert         : \\033[32m\n",
        "#Jaune        : \\033[33m\n",
        "#Bleu         : \\033[34m\n",
        "#Cyan         : \\033[36m\n",
        "#Gras         : \\033[1m\n",
        "#Italique     : \\033[3m\n",
        "#Réinit style : \\033[0m\n",
        "\n",
        "\n",
        "#Fonction de nettoyage de texte pour du Deep Learning : 1)Passage en minuscule / 2)Tokenisation / 3)Suppression des tokens de moins de X caractères / 4)Suppression des tokens trouvés plus de X fois / 5)Suppression des StopWords NLTK / 6) Lemmatisation ou Racinisation (ou rien du tout)\n",
        "#\n",
        "#INPUT :\n",
        "########\n",
        "#    _inputDataframe                      : dataframe Pandas source\n",
        "#    _inputFeaturesNames                  : Nom de la variable contenant des données textuelles à traiter\n",
        "#    _inputDropTokenIfLessThanXChars      : Nombre de caractère minimum pour un token (tous les tokens de moins de \"_inputDropTokenIfLessThanXChars\" caractères, seront supprimés)\n",
        "#                                                                               Si \"_inputDropTokenIfLessThanXChars\" = 0 --> On passe\n",
        "#    _inputDropTokenIfFoundMoreThanXTimes : Nombre d'occurence maximum d'un token (tous les tokens présents plus de \"_inputDropTokenIfFoundMoreThanXTimes\" fois, seront supprimés)\n",
        "#                                                                               Si \"_inputDropTokenIfFoundMoreThanXTimes\" = 0 --> On passe\n",
        "#    _inputLanguage                       : Langue dans laquelle on va télécharger le StopWords NLTK les plus courants (comme \"english\", par exemple)\n",
        "#                                                                               Si \"None\", alors on passe sans supprimer les StopWords (utile en DeepLearning)\n",
        "#    _inputLemmatizationOrStemmingChoice  : Choix du traitement des tokens : soit on procède à une \"Lemmatisation\" (_inputLemmatizationOrStemmingChoice=\"LEM\"),\n",
        "#                                                                            soit à une \"Racinisation\" (_inputLemmatizationOrStemmingChoice=\"STEM\"),\n",
        "#                                                                            soit ne RIEN FAIRE de plus (_inputLemmatizationOrStemmingChoice=\"NONE\")\n",
        "#\n",
        "#OUTPUT :\n",
        "#########\n",
        "#    Les tokens (qui ont été traités)\n",
        "#\n",
        "def _textCleaning(_inputDataframe, _inputFeaturesNames, _inputDropTokenIfLessThanXChars=0, _inputDropTokenIfFoundMoreThanXTimes=0, _inputLanguage=\"None\", _inputLemmatizationOrStemmingChoice=\"None\"):\n",
        "    #On va créer une copie pour ne pas modifier le DataFrame original\n",
        "    tempDataframe = _inputDataframe.copy()\n",
        "\n",
        "    #1ère étape : on passe tous les caractères en minuscules et on vire les caractères spéciaux !\n",
        "    tempDataframe[\"tokens\"] = tempDataframe[_inputFeaturesNames].astype(str).str.lower().fillna(\"\")\n",
        "    tempDataframe[\"tokens\"] = tempDataframe[\"tokens\"].str.replace(\"-\", \" \").str.replace(\"+\", \" \").str.replace(\"/\", \" \").str.replace(\"#\", \" \").str.replace(\"_\", \" \").str.replace(\"&\", \" \").str.replace(\"(\", \" \").str.replace(\")\", \" \").str.replace(\"@\", \" \")\n",
        "\n",
        "    #2ème étape : on ne garde que les mots constitués de caracètres alphabétiques (Tokenisation)\n",
        "    tokenizer = nltk.RegexpTokenizer(r\"[^\\W\\d_]+\")\n",
        "    tempDataframe[\"tokens\"] = tempDataframe[\"tokens\"].apply(tokenizer.tokenize)\n",
        "\n",
        "    #3ème étape : on vire les tokens de moins de \"_inputDropTokenIfLessThanXChars\" caractères\n",
        "    if(_inputDropTokenIfLessThanXChars != 0):\n",
        "        tempDataframe[\"tokens\"] = tempDataframe[\"tokens\"].apply(lambda tokens: [token for token in tokens if len(token) >= _inputDropTokenIfLessThanXChars])\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    #4ème étape : on virer les X tokens les plus fréquents\n",
        "    if(_inputDropTokenIfFoundMoreThanXTimes != 0):\n",
        "        #On met à plat toutes les listes de tokens en une seule grande liste\n",
        "        flattenTokens = [token for sublist in tempDataframe[\"tokens\"] for token in sublist]\n",
        "        #On compte les occurrences de chaque token\n",
        "        numberOfTokens = Counter(flattenTokens)\n",
        "        #On filtrer les tokens qui apparaissent X fois ou plus\n",
        "        filteredTokensList = [item for item in numberOfTokens.most_common() if item[1] >= _inputDropTokenIfFoundMoreThanXTimes]\n",
        "        mostCommonTokens = Counter(dict(filteredTokensList))\n",
        "        #DEBUG - DECOMMENTER CETTE LIGNE POUR AFFICHER LA LISTE DES TOKENS LES PLUS COURANTS\n",
        "        #display(mostCommonTokens)\n",
        "        #On converti les clés des tokens les plus courants en un ensemble\n",
        "        stopWords = set(mostCommonTokens.keys())\n",
        "        #On applique la suppression des StopWords à chaque liste de tokens dans la variable \"tokens\"\n",
        "        tempDataframe[\"tokens\"] = tempDataframe[\"tokens\"].apply(lambda tokens: [token for token in tokens if token not in stopWords])\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    #5ème étape : on télécharge les StopWords NLTK les plus courants de la langue \"_inputLanguage\", ou on passe si \"_inputLanguage\" == \"None\"\n",
        "    if(str(_inputLanguage).lower() != \"none\"):\n",
        "        nltk.download(\"stopwords\")\n",
        "        stopWords = set(stopwords.words(_inputLanguage))\n",
        "        #On applique la suppression des StopWords à chaque liste de tokens dans la variable \"tokens\"\n",
        "        tempDataframe[\"tokens\"] = tempDataframe[\"tokens\"].apply(lambda tokens: [token for token in tokens if token not in stopWords])\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    #6ème étape : on lemmatise (\"Lem\") ou on racinise (\"Stem\") les tokens, ou on ne fait rien du tout (\"None\")\n",
        "    if(str(_inputLemmatizationOrStemmingChoice).lower() == \"lem\"):\n",
        "        nltk.download(\"wordnet\")\n",
        "        print(\"***Lemmatization***\")\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        tempDataframe[\"tokens\"] = tempDataframe[\"tokens\"].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
        "    elif(str(_inputLemmatizationOrStemmingChoice).lower() == \"stem\"):\n",
        "        nltk.download(\"wordnet\")\n",
        "        print(\"***Stemming***\")\n",
        "        stemmer = PorterStemmer()\n",
        "        tempDataframe[\"tokens\"] = tempDataframe[\"tokens\"].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    #Display post-cleaning informations\n",
        "    flattenTokensList = [token for sublist in tempDataframe[\"tokens\"] for token in sublist]\n",
        "    print(\"Nombre total de tokens\\t\\t:\", len(flattenTokensList))\n",
        "    print(\"Nombre de tokens uniques\\t:\", len(Counter(flattenTokensList)))\n",
        "\n",
        "    return tempDataframe[\"tokens\"]"
      ],
      "metadata": {
        "id": "a0Tpg7wyGCNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partie 1 : installation du pipeline"
      ],
      "metadata": {
        "id": "09wj6zAlDXMk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On part du principe qu'on va utiliser Google Colab pour le développement, tout en liant le compte avec GitHub, dans lequel on a créé un repository public nommé [\"Projet_7-Air_Paradis-PUBLIC\"](https://github.com/Jojo31100/Projet_7-Air_Paradis-PUBLIC)\n"
      ],
      "metadata": {
        "id": "t87UePLOEO0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. MLflow"
      ],
      "metadata": {
        "id": "CELnOdImDcwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installation de MLFlow pour suivre la totalité des modèles (temps d'entrainement, d'inférence, résultats, meilleurs paramètres, ...)\n",
        "!pip install mlflow\n",
        "import mlflow\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "#On va créer les \"Experiments\" pour y stocker nos modèles\n",
        "#mlflow.set_experiment(\"Modeles-RegressionLogistique\")\n",
        "#mlflow.set_experiment(\"Modeles-DeepLearning\")"
      ],
      "metadata": {
        "id": "9TqQpsqNDh23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. ngrok"
      ],
      "metadata": {
        "id": "IMcFG4l4Xt6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installation de ngrok pour accéder à MLflow UI depuis Google Colab\n",
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "#Ferme toutes les instances précédentes de NGrok\n",
        "ngrok.kill()\n",
        "\n",
        "#Paramétrage du token\n",
        "ngrokAuthToken = \"30GdRuK989WiPWr5DbDm7Zv23eF_7j5moxUiutbaNa85GnjUP\"\n",
        "ngrok.set_auth_token(ngrokAuthToken)\n",
        "\n",
        "#On créé un nouveau tunnel sur le port 5000\n",
        "ngrokTunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"\\n\\nPour accéder à l'UI de MLflow, cliquez ici :\", ngrokTunnel.public_url, \"\\n---> Attendez quelques secondes, le temps que la UI se lance...\\n---> Dès que des lignes apparaissent ci-dessous, vous pourrez y aller, puis cliquez sur le bouton [Visit Site] ! ;)\\n\")\n",
        "\n",
        "#On démarre la UI\n",
        "!mlflow ui"
      ],
      "metadata": {
        "id": "8SjITG7PXyZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partie 2 : analyse Exploratoire des Données"
      ],
      "metadata": {
        "id": "YkADdhdgGi7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Connexion à Google Drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "\n",
        "#Comme le dataset fourni ne contient pas la 1ère ligne avec les noms des variables, on va préparer le dataframe Pandas manuellement, en les rajoutants\n",
        "nomsVariables = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"] #Informations trouvées ici : https://www.kaggle.com/datasets/kazanova/sentiment140\n",
        "\n",
        "#On charge nos données\n",
        "dataframe = pandas.read_csv(\"/content/drive/My Drive/Colab_Notebooks/Project_7/dataset/training.1600000.processed.noemoticon.csv\", encoding=\"latin-1\", header=None, names=nomsVariables)\n",
        "dataframe.shape"
      ],
      "metadata": {
        "id": "5gsu2sqoGt4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_visualisationDataset(dataframe, 100, \"Yes\")"
      ],
      "metadata": {
        "id": "pQxTzeSJHM7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D'emblée, on constate déjà beaucoup de choses :\n",
        "1. Les variables \"ids\", \"date\", \"flag\", \"user\" ne nous serviront sans doute pas à grand chose...\n",
        "2. La base est énorme :  1,6 millions de tweets\n",
        "3. La variable target semble équilibrée (valeur min=0 / valeur max=4 / moyenne=2 ; Ce qui signifie qu'il y a autant de 0 que de 4 !)\n",
        "4. La variable \"flag\" ne sera, pour sûr, d'absolument AUCUNE utilité (1 seule valeur sur l'ensemble du dataset !)\n",
        "\n",
        "Donc, les variables intéressantes seront :\n",
        "- \"target\" (la target à prédire : 0=Tweet négatif / 4=Tweet positif)\n",
        "- \"text\" (les données d'entraînement/validation/test)"
      ],
      "metadata": {
        "id": "7OKAcCsXLXF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partie 3 : construction de datasets pour l'entrainement/la validation et le test de nos modèles"
      ],
      "metadata": {
        "id": "0eW_LI3hmxs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entraîner la totalité de nos modèles sur les 1,6 millions de tweets paraît chronophage et pas forcément utile.\n",
        "\n",
        "On va donc faire un sous-échantillon (équivalent à 5% du dataset de base), de 80 000 tweets.\n",
        "\n",
        "Ce qui devrait être amplement suffisant pour entrainer/valider et tester nos différents modèles (avant de sélectionner le meilleur modèle et de le tester sur l'entièreté du dataset.\n",
        "\n",
        "Il sera important toutefois de procéder à un mélange aléatoire (mais reproductible) des données : la target étant négative sur les 50 premiers pourcents du dataset, et positive sur les 50% restants."
      ],
      "metadata": {
        "id": "Hw2y-sLrnDBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sous-échantillonnage de 80 000 individus (5% des 1,6 million de Tweets), stratifié sur la variable \"target\"\n",
        "subDataframe_TrainVal, subDataframe_Test = train_test_split(dataframe, train_size=80000, stratify=dataframe[\"target\"], random_state=23011977)"
      ],
      "metadata": {
        "id": "AOKi62xini6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_visualisationDataset(subDataframe_TrainVal, 100, \"Yes\")"
      ],
      "metadata": {
        "id": "MGJAmnApS_7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_visualisationDataset(subDataframe_Test, 100, \"Yes\")"
      ],
      "metadata": {
        "id": "DQi5FtgerHzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partie 4 : pré-traitement du texte"
      ],
      "metadata": {
        "id": "nh2N27F7uXbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sur le dataframe d'entraînement et de validation\n",
        "#On passe le texte dans la fonction de nettoyage/tokensisation/lemmatisation pour le Bag of Words ou l'Embedding\n",
        "print(\"\\nTraitement textuel : Bag of Words/Embedding + Lemmatisation\")\n",
        "subDataframe_TrainVal[\"Bag_of_Words_Lemmatise\"] = _textCleaning(subDataframe_TrainVal, \"text\", 0, 0, \"english\", \"Lem\") #Pour l'instant, on ne supprime pas les mots de moins de X caractères ou présent plus de X fois (on reviendra adapter si nécessaire)\n",
        "subDataframe_TrainVal[\"Bag_of_Words_Lemmatise\"] = subDataframe_TrainVal[\"Bag_of_Words_Lemmatise\"].apply(lambda tokens: \" \".join(tokens))\n",
        "\n",
        "#On passe le texte dans la fonction de nettoyage/tokensisation/racinisation pour le Bag of Words ou l'Embedding\n",
        "print(\"\\nTraitement textuel : Bag of Words/Embedding + Racinisation\")\n",
        "subDataframe_TrainVal[\"Bag_of_Words_Racinise\"] = _textCleaning(subDataframe_TrainVal, \"text\", 0, 0, \"english\", \"Stem\") #Pour l'instant, on ne supprime pas les mots de moins de X caractères ou présent plus de X fois (on reviendra adapter si nécessaire)\n",
        "subDataframe_TrainVal[\"Bag_of_Words_Racinise\"] = subDataframe_TrainVal[\"Bag_of_Words_Racinise\"].apply(lambda tokens: \" \".join(tokens))\n",
        "\n",
        "#On passe le texte dans la fonction de nettoyage/tokensisation pour le Deep Learning\n",
        "print(\"\\nTraitement textuel : Deep Learning\")\n",
        "subDataframe_TrainVal[\"Texte_DeepLearning\"] = _textCleaning(subDataframe_TrainVal, \"text\", 0, 0, \"None\", \"None\") #Pour l'instant, on ne supprime pas les mots de moins de X caractères ou présent plus de X fois (on reviendra adapter si nécessaire)\n",
        "subDataframe_TrainVal[\"Texte_DeepLearning\"] = subDataframe_TrainVal[\"Texte_DeepLearning\"].apply(lambda tokens: \" \".join(tokens))"
      ],
      "metadata": {
        "id": "H571eOGmvhKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subDataframe_TrainVal"
      ],
      "metadata": {
        "id": "iaQefHkNxVLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sur le dataframe de test\n",
        "#On passe le texte dans la fonction de nettoyage/tokensisation/lemmatisation pour le Bag of Words ou l'Embedding\n",
        "print(\"\\nTraitement textuel : Bag of Words/Embedding + Lemmatisation\")\n",
        "subDataframe_Test[\"Bag_of_Words_Lemmatise\"] = _textCleaning(subDataframe_Test, \"text\", 0, 0, \"english\", \"Lem\") #Pour l'instant, on ne supprime pas les mots de moins de X caractères ou présent plus de X fois (on reviendra adapter si nécessaire)\n",
        "subDataframe_Test[\"Bag_of_Words_Lemmatise\"] = subDataframe_Test[\"Bag_of_Words_Lemmatise\"].apply(lambda tokens: \" \".join(tokens))\n",
        "\n",
        "#On passe le texte dans la fonction de nettoyage/tokensisation/racinisation pour le Bag of Words ou l'Embedding\n",
        "print(\"\\nTraitement textuel : Bag of Words/Embedding + Racinisation\")\n",
        "subDataframe_Test[\"Bag_of_Words_Racinise\"] = _textCleaning(subDataframe_Test, \"text\", 0, 0, \"english\", \"Stem\") #Pour l'instant, on ne supprime pas les mots de moins de X caractères ou présent plus de X fois (on reviendra adapter si nécessaire)\n",
        "subDataframe_Test[\"Bag_of_Words_Racinise\"] = subDataframe_Test[\"Bag_of_Words_Racinise\"].apply(lambda tokens: \" \".join(tokens))\n",
        "\n",
        "#On passe le texte dans la fonction de nettoyage/tokensisation pour le Deep Learning\n",
        "print(\"\\nTraitement textuel : Deep Learning\")\n",
        "subDataframe_Test[\"Texte_DeepLearning\"] = _textCleaning(subDataframe_Test, \"text\", 0, 0, \"None\", \"None\") #Pour l'instant, on ne supprime pas les mots de moins de X caractères ou présent plus de X fois (on reviendra adapter si nécessaire)\n",
        "subDataframe_Test[\"Texte_DeepLearning\"] = subDataframe_Test[\"Texte_DeepLearning\"].apply(lambda tokens: \" \".join(tokens))"
      ],
      "metadata": {
        "id": "vu05G7YWTe8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subDataframe_Test"
      ],
      "metadata": {
        "id": "XS-Ivyc3UJk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#On va supprimer les individus dont tout le texte aurait été supprimé\n",
        "#... dans le dataset de train/validation\n",
        "subDataframe_TrainVal = subDataframe_TrainVal[~subDataframe_TrainVal[\"Bag_of_Words_Lemmatise\"].astype(str).isin([\"\", \"nan\", \"NaN\", \"None\"])]\n",
        "subDataframe_TrainVal = subDataframe_TrainVal[~subDataframe_TrainVal[\"Bag_of_Words_Racinise\"].astype(str).isin([\"\", \"nan\", \"NaN\", \"None\"])]\n",
        "subDataframe_TrainVal = subDataframe_TrainVal[~subDataframe_TrainVal[\"Texte_DeepLearning\"].astype(str).isin([\"\", \"nan\", \"NaN\", \"None\"])]\n",
        "#... ainsi que dans le dataset de test\n",
        "subDataframe_Test = subDataframe_Test[~subDataframe_Test[\"Bag_of_Words_Lemmatise\"].astype(str).isin([\"\", \"nan\", \"NaN\", \"None\"])]\n",
        "subDataframe_Test = subDataframe_Test[~subDataframe_Test[\"Bag_of_Words_Racinise\"].astype(str).isin([\"\", \"nan\", \"NaN\", \"None\"])]\n",
        "subDataframe_Test = subDataframe_Test[~subDataframe_Test[\"Texte_DeepLearning\"].astype(str).isin([\"\", \"nan\", \"NaN\", \"None\"])]\n",
        "\n",
        "#On va enregistrer nos sous-échantillons en tant que fichiers .CSV,\n",
        "#afin de pouvoir les recharger pour l'entrainement ou l'inférence de nos modèles,\n",
        "#sans avoir à repasser par toute la phase de préparation...\n",
        "subDataframe_TrainVal.to_csv(\"/content/drive/My Drive/Colab_Notebooks/Project_7/dataset/TextPrepared_Dataset_TrainVal.csv\", index=False, sep=\";\")\n",
        "subDataframe_Test.to_csv(\"/content/drive/My Drive/Colab_Notebooks/Project_7/dataset/TextPrepared_Dataset_Test.csv\", index=False, sep=\";\")"
      ],
      "metadata": {
        "id": "RCENlhkcR8j4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partie 5 : Tests \"manuels\" avec MLflow [DRAFT]"
      ],
      "metadata": {
        "id": "6_9PEHhtX_t0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Connexion à Google Drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "\n",
        "#On charge nos données\n",
        "dataframe = pandas.read_csv(\"/content/drive/My Drive/Colab_Notebooks/Project_7/dataset/TextPrepared_Dataset_TrainVal.csv\", sep=\";\")\n",
        "dataframe.shape"
      ],
      "metadata": {
        "id": "I9jVet9oYKDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe"
      ],
      "metadata": {
        "id": "osixV6aJYmj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, on a bien récupéré notre sous-échantillon d'environ 80 000 Tweets destinés à l'entrainement et à la validation !"
      ],
      "metadata": {
        "id": "s8VxpxWjYrGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Regression logistique sur le Bag of Words Lemmatisé/Racinisé - Sauvegardée dans MLflow\n",
        "\n",
        "\n",
        "#Définition des données X et y\n",
        "X = dataframe[[\"Bag_of_Words_Racinise\"]] #Bag_of_Words_Lemmatise\"]]\n",
        "y = dataframe[\"target\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=23011977)\n",
        "\n",
        "#Vectorisation en Bag of Words\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vect = vectorizer.fit_transform(X_train[\"Bag_of_Words_Racinise\"]) #Bag_of_Words_Lemmatise\"])\n",
        "X_test_vect = vectorizer.transform(X_test[\"Bag_of_Words_Racinise\"]) #Bag_of_Words_Lemmatise\"])\n",
        "\n",
        "#Entraînement du modèle\n",
        "mlflow.set_experiment(\"Modeles-RegressionLogistique\")\n",
        "mlflow.sklearn.autolog()\n",
        "with mlflow.start_run(run_name=\"Regression_Logistique-max_iter_1000-BoW_Racinise\"):\n",
        "    modeleRegressionLogistique = LogisticRegression(class_weight=\"balanced\", max_iter=1000, random_state=23011977)\n",
        "    modeleRegressionLogistique.fit(X_train_vect, y_train.values)\n",
        "    #Inférence\n",
        "    y_pred = modeleRegressionLogistique.predict(X_test_vect)\n",
        "    y_proba = modeleRegressionLogistique.predict_proba(X_test_vect)[:, 1]\n",
        "\n",
        "    #Logging manuel des métriques liés aux prédictions sur le dataset de validation\n",
        "    mlflow.log_metric(\"validation_accuracy_score\", accuracy_score(y_test, y_pred))\n",
        "    mlflow.log_metric(\"validation_f1_score\", f1_score(y_test, y_pred, pos_label=4))\n",
        "    mlflow.log_metric(\"validation_precision_score\", precision_score(y_test, y_pred, pos_label=4))\n",
        "    mlflow.log_metric(\"validation_recall_score\", recall_score(y_test, y_pred, pos_label=4))\n",
        "    mlflow.log_metric(\"validation_roc_auc\", roc_auc_score(y_test, y_proba))"
      ],
      "metadata": {
        "id": "DcsmvYF-1QF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Métriques\n",
        "\n",
        "#Accuracy\n",
        "print(\"Accuracy\\t:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "#ROC AUC score\n",
        "print(\"\\nROC AUC score\\t:\", roc_auc_score(y_test, y_proba))\n",
        "\n",
        "#Rapport de classification\n",
        "print(\"\\nRapport de classification :\\n\", classification_report(y_test, y_pred, target_names=[\"Négatif\", \"Positif\"]), sep=\"\")\n",
        "\n",
        "#Matrice de confusion\n",
        "matriceDeConfusion = confusion_matrix(y_test, y_pred)\n",
        "seaborn.heatmap(matriceDeConfusion, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Négatif\", \"Positif\"], yticklabels=[\"Négatif\", \"Positif\"])\n",
        "matplotlib.pyplot.title(\"Matrice de confusion\")\n",
        "matplotlib.pyplot.xlabel(\"Prédit\")\n",
        "matplotlib.pyplot.ylabel(\"Réel\")\n",
        "matplotlib.pyplot.show()\n",
        "\n",
        "#ROC-AUC & AUC\n",
        "fauxPositifs, vraisPositifs, thresholds = roc_curve(y_test, y_proba, pos_label=4)\n",
        "roc_auc = auc(fauxPositifs, vraisPositifs)\n",
        "matplotlib.pyplot.figure()\n",
        "matplotlib.pyplot.plot(fauxPositifs, vraisPositifs, color=\"darkorange\", lw=2, label=f\"Courbes ROC (AUC = {roc_auc:.4f})\")\n",
        "matplotlib.pyplot.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
        "matplotlib.pyplot.xlim([-0.01, 1.01])\n",
        "matplotlib.pyplot.ylim([-0.01, 1.01])\n",
        "matplotlib.pyplot.xlabel(\"Taux de Faux Positifs\")\n",
        "matplotlib.pyplot.ylabel(\"Taux de Vrais Positifs\")\n",
        "matplotlib.pyplot.title(\"Courbes ROC\")\n",
        "matplotlib.pyplot.legend(loc=\"lower right\")\n",
        "matplotlib.pyplot.grid(True)\n",
        "matplotlib.pyplot.show()"
      ],
      "metadata": {
        "id": "6H0XAi8_Y89t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vérifications faites : les métriques sont bien les mêmes que sur MLflow ! Yessss !\n",
        "\n",
        "Prochaine étape : refaire le modèle de Régression Linéaire, mais cette fois, avec recheche des meilleurs hyper-paramètres et cross-validation, le tout en utilisant notre ami GridSearchCV, bien évidemment !"
      ],
      "metadata": {
        "id": "F6GTINxqgRTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partie 5bis : \"Modèle sur mesure simple\" - Création, entraînement et inférence de notre 1er modèle (Régression Logistique)"
      ],
      "metadata": {
        "id": "-yV5wB7Nip_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 : Recherche des meilleurs hyper-paramètres & validation croisée avec GridSearchCV"
      ],
      "metadata": {
        "id": "EoCOtbt6rJ3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Connexion à Google Drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "\n",
        "#On charge nos données\n",
        "dataframe = pandas.read_csv(\"/content/drive/My Drive/Colab_Notebooks/Project_7/dataset/TextPrepared_Dataset_TrainVal.csv\", sep=\";\")\n",
        "dataframe.shape"
      ],
      "metadata": {
        "id": "7UNnBXs_rWGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe"
      ],
      "metadata": {
        "id": "tWIlT4hxra7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Petit rappel du \"*pourquoi*\" on priorise l'Accuracy sur nos modèles :\n",
        "- <u>**Accuracy**</u> :\n",
        "  - Les classes sont équilibrées et toutes les erreurs ont le même coût\n",
        "- <u>**Precision**</u> :\n",
        "  - On veut éviter les faux positifs (prédire 1 alors que c’est 0)\n",
        "- <u>**Recall**</u> :\n",
        "  - On veut éviter les faux négatifs (prédire 0 alors que c’est 1)\n",
        "- <u>**F1 Score**</u> :\n",
        "  - On veut trouver un compromis entre précision et rappel, surtout quand les classes sont déséquilibrées\n",
        "- <u>**ROC AUC**</u> :\n",
        "  - On veut un résumé global de la capacité du modèle à distinguer les classes (très utile pour la comparaison de modèles). Ne dépend pas du seuil"
      ],
      "metadata": {
        "id": "ijz16IAl5cub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Regression logistique (recherche des meilleurs hyper-paramètres et validation croisée) sur le Bag of Words LEMMATISE - Sauvegardée dans MLflow\n",
        "\n",
        "\n",
        "#Définition des données X et y\n",
        "X = dataframe[[\"Bag_of_Words_Lemmatise\"]]\n",
        "y = dataframe[\"target\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=23011977)\n",
        "\n",
        "#Vectorisation en Bag of Words\n",
        "vectorizer = TfidfVectorizer() #CountVectorizer() #\n",
        "X_train_vect = vectorizer.fit_transform(X_train[\"Bag_of_Words_Lemmatise\"])\n",
        "X_test_vect = vectorizer.transform(X_test[\"Bag_of_Words_Lemmatise\"])\n",
        "\n",
        "\n",
        "#Hyperparamètres à tester pour la Régression Logistique\n",
        "hyperParametres = {\n",
        "    \"C\": [0.01, 0.1, 1, 10],\n",
        "    \"penalty\": [\"l2\"],\n",
        "    \"solver\": [\"lbfgs\"],\n",
        "    \"max_iter\": [500, 1000]\n",
        "}\n",
        "\n",
        "#Entraînement du modèle\n",
        "mlflow.set_experiment(\"Modeles-RegressionLogistique\")\n",
        "mlflow.sklearn.autolog(max_tuning_runs=(5)) #On ne garde que les 5 meilleures combinaisons\n",
        "with mlflow.start_run(run_name=\"TFIDF-Cross_Validation-BoW_Lemmatise\"): #CountVectorizer-Cross_Validation-BoW_Lemmatise\"): #\n",
        "    gscvModel = GridSearchCV(LogisticRegression(class_weight=\"balanced\", random_state=23011977), hyperParametres, scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=1)\n",
        "    gscvModel.fit(X_train_vect, y_train.values)\n",
        "    bestModel = gscvModel.best_estimator_\n",
        "    mlflow.log_params(gscvModel.best_params_)\n",
        "    mlflow.log_param(\"test_size\", 0.25)\n",
        "    mlflow.log_param(\"random_state\", 23011977)\n",
        "\n",
        "    #Inférence\n",
        "    y_pred = bestModel.predict(X_test_vect)\n",
        "    y_proba = bestModel.predict_proba(X_test_vect)[:, 1]\n",
        "\n",
        "    #Logging manuel des métriques liés aux prédictions sur le dataset de validation\n",
        "    mlflow.log_metric(\"validation_accuracy_score\", accuracy_score(y_test, y_pred))\n",
        "    mlflow.log_metric(\"validation_f1_score\", f1_score(y_test, y_pred, pos_label=4))\n",
        "    mlflow.log_metric(\"validation_precision_score\", precision_score(y_test, y_pred, pos_label=4))\n",
        "    mlflow.log_metric(\"validation_recall_score\", recall_score(y_test, y_pred, pos_label=4))\n",
        "    mlflow.log_metric(\"validation_roc_auc\", roc_auc_score(y_test, y_proba))\n",
        "\n",
        "    #Sauvegarde du meilleur modèle dans MLflow\n",
        "    #mlflow.sklearn.log_model(bestModel, name=\"Meilleur_Modele-BoW_Lemmatise\")\n",
        "\n",
        "    #Sauvegarde du meilleur modèle (et de son vectorizer) dans MLflow\n",
        "    pipeline = Pipeline([(\"vectorizer\", vectorizer), (\"model\", bestModel)])\n",
        "    mlflow.sklearn.log_model(pipeline, name=\"Pipeline-TFIDF-BoW_Lemmatise\") #Pipeline-CountVectorizer-BoW_Lemmatise\") #"
      ],
      "metadata": {
        "id": "FpwkDRsXe4BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Regression logistique (recherche des meilleurs hyper-paramètres et validation croisée) sur le Bag of Words RACINISE - Sauvegardée dans MLflow\n",
        "\n",
        "\n",
        "#Définition des données X et y\n",
        "X = dataframe[[\"Bag_of_Words_Racinise\"]]\n",
        "y = dataframe[\"target\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=23011977)\n",
        "\n",
        "#Vectorisation en Bag of Words\n",
        "vectorizer = TfidfVectorizer() #CountVectorizer() #\n",
        "X_train_vect = vectorizer.fit_transform(X_train[\"Bag_of_Words_Racinise\"])\n",
        "X_test_vect = vectorizer.transform(X_test[\"Bag_of_Words_Racinise\"])\n",
        "\n",
        "\n",
        "#Hyperparamètres à tester pour la Régression Logistique\n",
        "hyperParametres = {\n",
        "    \"C\": [0.01, 0.1, 1, 10],\n",
        "    \"penalty\": [\"l2\"],\n",
        "    \"solver\": [\"lbfgs\"],\n",
        "    \"max_iter\": [500, 1000]\n",
        "}\n",
        "\n",
        "#Entraînement du modèle\n",
        "mlflow.set_experiment(\"Modeles-RegressionLogistique\")\n",
        "mlflow.sklearn.autolog(max_tuning_runs=(5)) #On ne garde que les 5 meilleures combinaisons\n",
        "with mlflow.start_run(run_name=\"TFIDF-Cross_Validation-BoW_Racinise\"): #CountVectorizer-Cross_Validation-BoW_Racinise\"): #\n",
        "    gscvModel = GridSearchCV(LogisticRegression(class_weight=\"balanced\", random_state=23011977), hyperParametres, scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=1)\n",
        "    gscvModel.fit(X_train_vect, y_train.values)\n",
        "    bestModel = gscvModel.best_estimator_\n",
        "    mlflow.log_params(gscvModel.best_params_)\n",
        "    mlflow.log_param(\"test_size\", 0.25)\n",
        "    mlflow.log_param(\"random_state\", 23011977)\n",
        "\n",
        "    #Inférence\n",
        "    y_pred = bestModel.predict(X_test_vect)\n",
        "    y_proba = bestModel.predict_proba(X_test_vect)[:, 1]\n",
        "\n",
        "    #Logging manuel des métriques liés aux prédictions sur le dataset de validation\n",
        "    mlflow.log_metric(\"validation_accuracy_score\", accuracy_score(y_test, y_pred))\n",
        "    mlflow.log_metric(\"validation_f1_score\", f1_score(y_test, y_pred, pos_label=4))\n",
        "    mlflow.log_metric(\"validation_precision_score\", precision_score(y_test, y_pred, pos_label=4))\n",
        "    mlflow.log_metric(\"validation_recall_score\", recall_score(y_test, y_pred, pos_label=4))\n",
        "    mlflow.log_metric(\"validation_roc_auc\", roc_auc_score(y_test, y_proba))\n",
        "\n",
        "    #Sauvegarde du meilleur modèle dans MLflow\n",
        "    #mlflow.sklearn.log_model(bestModel, name=\"Meilleur_Modele-BoW_Racinise\")\n",
        "\n",
        "    #Sauvegarde du meilleur modèle (et de son vectorizer) dans MLflow\n",
        "    pipeline = Pipeline([(\"vectorizer\", vectorizer), (\"model\", bestModel)])\n",
        "    mlflow.sklearn.log_model(pipeline, name=\"Pipeline-TFIDF-BoW_Racinise\") #Pipeline-CountVectorizer-BoW_Racinise\") #"
      ],
      "metadata": {
        "id": "jLlpwSLUrbqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 : Rechargement du meilleur modèle de Régression Logistique depuis MLflow"
      ],
      "metadata": {
        "id": "KRqRxb8UOied"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Connexion à Google Drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "\n",
        "#On charge nos données\n",
        "dataframe = pandas.read_csv(\"/content/drive/My Drive/Colab_Notebooks/Project_7/dataset/TextPrepared_Dataset_Test.csv\", sep=\";\")\n",
        "dataframe.shape"
      ],
      "metadata": {
        "id": "kvlmUnJTPHfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe"
      ],
      "metadata": {
        "id": "27uXOqNHPIAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rechargement du meilleur modèle dans MLflow\n",
        "\n",
        "#Connexion au client MLflow\n",
        "client = MlflowClient()\n",
        "\n",
        "#Recherche de l'expérience\n",
        "experiments = client.get_experiment_by_name(\"Modeles-RegressionLogistique\")\n",
        "\n",
        "#Récupération des Runs triés par Accuracy décroissante\n",
        "runs = client.search_runs(experiment_ids=[experiments.experiment_id], order_by=[\"metrics.validation_accuracy_score DESC\"])\n",
        "\n",
        "#Récupère le meilleur Run\n",
        "bestRun = runs[0]\n",
        "bestRunId = bestRun.info.run_id\n",
        "\n",
        "#Chemin vers le pipeline enregistré (vectorisation + modèle)\n",
        "modelPath = f\"runs:/{bestRunId}/Pipeline-TFIDF-BoW_Racinise\"\n",
        "\n",
        "# Recharge le pipeline complet\n",
        "RegressionLogistiquePipeline = mlflow.sklearn.load_model(modelPath)"
      ],
      "metadata": {
        "id": "gWG1rTPFPIPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Affichage d'infos sur le modèle chargé\n",
        "\n",
        "#Récupération des infos du Run\n",
        "runInfos = client.get_run(bestRunId)\n",
        "\n",
        "#Nom de l'Expérience et du Run\n",
        "print(\"Expérience sélectionnée\\t:\", client.get_experiment(runInfos.info.experiment_id).name)\n",
        "print(\"Modèle chargé\\t\\t:\", runInfos.data.tags[\"mlflow.runName\"])\n",
        "print(\"-\"*150)\n",
        "\n",
        "#Hyper Paramètres\n",
        "print(\"Hyper Paramètres testés\\t\\t:\", runInfos.data.params[\"param_grid\"])\n",
        "print(\"Scoring retenu\\t\\t\\t:\", runInfos.data.params[\"scoring\"])\n",
        "print(\"Meilleurs hyper-paramètres\\t:\")\n",
        "for param, value in sorted(runInfos.data.params.items()):\n",
        "    if param.startswith(\"best\"):\n",
        "        print(\"\\t\\t\\t\\t --> \", param, \":\", value)\n",
        "print(\"-\"*150)\n",
        "\n",
        "#Métriques\n",
        "print(\"Métriques du modèles :\")\n",
        "for metric, value in sorted(runInfos.data.metrics.items()):\n",
        "    print(\"\\t\", metric, \"=\", round(value, 2))"
      ],
      "metadata": {
        "id": "V_kN8P7ZTIEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Utilisation du pipeline \"à la mano\" pour tester\n",
        "nouveauxTweets = [\"I am very sad today, the weather is horrible\", \"Too happy, it's my birthday, and all my best friends sent me a wonderful gift !\"]\n",
        "\n",
        "# rédictions\n",
        "predictions = RegressionLogistiquePipeline.predict(nouveauxTweets)\n",
        "probas = RegressionLogistiquePipeline.predict_proba(nouveauxTweets)[:, 1]\n",
        "\n",
        "#Affichage\n",
        "for txt, pred, proba in zip(nouveauxTweets, predictions, probas):\n",
        "    print(\"Texte :\", txt)\n",
        "    print(\"Classe prédite : \", pred, \"\\n --> Probabilité classe 0 (NEGATIVE) = \", round((1-proba)*100, 2), \"%\\n --> Probabilité classe 4 (POSITIVE) = \", round(proba*100, 2), \"%\\n\", sep=\"\")"
      ],
      "metadata": {
        "id": "5F44Cy8yhe2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "J'adoooooore, ça marche trop bien ! :)"
      ],
      "metadata": {
        "id": "fJcyHwc1s164"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 : Test du meilleur modèle (pipeline Vectorizer + Régression Logistique) sur les données de test (1,5 millions de Tweets)"
      ],
      "metadata": {
        "id": "QfbHX-wUneOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Définition des données X et y\n",
        "X_test = dataframe[\"Bag_of_Words_Racinise\"]\n",
        "y_test = dataframe[\"target\"]\n",
        "\n",
        "#Pédictions avec le pipeline MLflow\n",
        "y_pred = RegressionLogistiquePipeline.predict(X_test)\n",
        "y_proba = RegressionLogistiquePipeline.predict_proba(X_test)[:, 1]"
      ],
      "metadata": {
        "id": "ZQhQk9xUnv2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Métriques\n",
        "\n",
        "#Accuracy\n",
        "print(\"Accuracy\\t:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "#ROC AUC score\n",
        "print(\"\\nROC AUC score\\t:\", roc_auc_score(y_test, y_proba))\n",
        "\n",
        "#Rapport de classification\n",
        "print(\"\\nRapport de classification :\\n\", classification_report(y_test, y_pred, target_names=[\"Négatif\", \"Positif\"]), sep=\"\")\n",
        "\n",
        "#Matrice de confusion\n",
        "matriceDeConfusion = confusion_matrix(y_test, y_pred)\n",
        "seaborn.heatmap(matriceDeConfusion, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Négatif\", \"Positif\"], yticklabels=[\"Négatif\", \"Positif\"])\n",
        "matplotlib.pyplot.title(\"Matrice de confusion\")\n",
        "matplotlib.pyplot.xlabel(\"Prédit\")\n",
        "matplotlib.pyplot.ylabel(\"Réel\")\n",
        "matplotlib.pyplot.show()\n",
        "\n",
        "#ROC-AUC & AUC\n",
        "fauxPositifs, vraisPositifs, thresholds = roc_curve(y_test, y_proba, pos_label=4)\n",
        "roc_auc = auc(fauxPositifs, vraisPositifs)\n",
        "matplotlib.pyplot.figure()\n",
        "matplotlib.pyplot.plot(fauxPositifs, vraisPositifs, color=\"darkorange\", lw=2, label=f\"Courbes ROC (AUC = {roc_auc:.4f})\")\n",
        "matplotlib.pyplot.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
        "matplotlib.pyplot.xlim([-0.01, 1.01])\n",
        "matplotlib.pyplot.ylim([-0.01, 1.01])\n",
        "matplotlib.pyplot.xlabel(\"Taux de Faux Positifs\")\n",
        "matplotlib.pyplot.ylabel(\"Taux de Vrais Positifs\")\n",
        "matplotlib.pyplot.title(\"Courbes ROC\")\n",
        "matplotlib.pyplot.legend(loc=\"lower right\")\n",
        "matplotlib.pyplot.grid(True)\n",
        "matplotlib.pyplot.show()"
      ],
      "metadata": {
        "id": "1LIDfmKpouKX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}